{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a9c3d9",
   "metadata": {},
   "source": [
    "# Building your own recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef49deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9385b",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb74c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'google_books_1299.csv'\n",
    "\n",
    "def get_data(path_to_data):\n",
    "\n",
    "    data = pd.read_csv(f'{path_to_data}',index_col=0)\n",
    "    data[\"title\"] = data[\"title\"].str.lower()\n",
    "    data = data.dropna()\n",
    "    data.index = [i for i in range(0,len(data))]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281cda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16337112",
   "metadata": {},
   "source": [
    "# Create a content-based recommender system using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e66347df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "data['generes'] = data['generes'].astype('string')\n",
    "data['preprocessed_genre'] = data['generes'].apply(\n",
    "    lambda genre: simple_preprocess(genre.replace('&', '').replace('amp', '').replace(',', '').replace('none', ''), min_len=3) if type(genre) is str else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbaa19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc225ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This framework provides an easy method to compute dense vector representations for sentences.The models are based on transformer networks like BERT.Text is embedding in vector space such that similar text is close and can efficiently be found using cosine similarity.\n",
    "from sentence_transformers import SentenceTransformer \n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45560a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(genres, data):\n",
    "    book_dic = {} #create a dictionary\n",
    "    \n",
    "    for index, value in data.iterrows(): #.iterrows: Iterate over DataFrame rows as (index, Series) pairs. -read the DataFrame row by row\n",
    "        genres_embeddings = model.encode([genres]) #encode genres\n",
    "        value_embeddings = model.encode(', '.join([str(elem) for elem in value[13]])) #encode the values in genres\n",
    "        cosine = 1 - spatial.distance.cosine(genres_embeddings, value_embeddings) #1- cosine distance between the two =similarity\n",
    "        if cosine > 0.7: \n",
    "            if index in book_dic.keys():\n",
    "                continue\n",
    "            else:\n",
    "                book_dic[index] = float(value[2]) #list the books from high to low rate\n",
    "        else:\n",
    "            continue\n",
    "    if book_dic and len(list(book_dic.keys()))>=5: #condition when there are more than 5 qualified books\n",
    "        book_dic = dict(sorted(book_dic.items(), key=lambda x: x[1], reverse=True)) #list the books from high to low cosine value\n",
    "        book_indexs = list(book_dic.keys())[:5] #show the top 5 books\n",
    "        recommendation = pd.DataFrame(columns=['ISBN','title']) #create colunms and the format shown is ISBN,title\n",
    "        for book_index in book_indexs:\n",
    "            book_ISBN = data['ISBN'].iloc[book_index] #map the 'ISBN' according to the book index\n",
    "            book_title = data['title'].iloc[book_index] #map the 'title' according to the book index\n",
    "            recommendation=recommendation.append({'ISBN' : book_ISBN , 'title' : book_title} , ignore_index=True) #append the list     \n",
    "        return recommendation\n",
    "    elif book_dic:\n",
    "        print(\"We can only give you less than 5 recommendations\") #condition when there are less than 5 qualified books \n",
    "        book_dic = dict(sorted(book_dic.items(), key=lambda x: x[1], reverse=True))\n",
    "        book_indexs = list(book_dic.keys())\n",
    "        recommendation = pd.DataFrame(columns=['ISBN','title'])\n",
    "        for book_index in book_indexs:\n",
    "            book_ISBN = data['ISBN'].iloc[book_index]\n",
    "            book_title = data['title'].iloc[book_index]\n",
    "            recommendation=recommendation.append({'ISBN' : book_ISBN , 'title' : book_title} , ignore_index=True)      \n",
    "        return recommendation\n",
    "        \n",
    "    else:\n",
    "        recommendation = \"Sorry, we do not have any recommentation for you.\"\n",
    "        return recommendation\n",
    "        \n",
    "def Content_based_recommender(data):\n",
    "\n",
    "    data = data[data['preprocessed_genre'].notna()] #drop the missing value\n",
    "    genres_set = set()\n",
    "    for i in data['preprocessed_genre']:\n",
    "        for genre in i:\n",
    "            genres_set.add(genre)\n",
    "    \n",
    "    print(f\"What type of genre do you like? \\n\\nYou can choose from the following:\\n\\n{genres_set}\")\n",
    "    genres = input().lower()\n",
    "    \n",
    "    recommendations = recommender(genres, data)\n",
    "\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Content_based_recommender(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaf4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a639c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fbf10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cab222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2f088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
